{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory hiercharchy\n",
    "\n",
    "- Processor registers – the fastest possible access (usually 1 CPU cycle). A few thousand bytes in size\n",
    "- Cache\n",
    "    - Level 0 (L0) Micro operations cache – 6 KiB in size\n",
    "    - Level 1 (L1) Instruction cache – 128 KiB in size\n",
    "    - Level 1 (L1) Data cache – 128 KiB in size. Best access speed is around 700 GiB/second\n",
    "    - Level 2 (L2) Instruction and data (shared) – 1 MiB in size. Best access speed is around 200 GiB/second\n",
    "    - Level 3 (L3) Shared cache – 6 MiB in size. Best access speed is around 100 GB/second\n",
    "    - Level 4 (L4) Shared cache – 128 MiB in size. Best access speed is around 40 GB/second\n",
    "- Main memory (Primary storage) – Gigabytes in size. Best access speed is around 10 GB/second.\n",
    "- Disk storage (Secondary storage) – Terabytes in size. As of 2017, best access speed is from a consumer solid state drive is about 2000 MB/second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linked list\n",
    "\n",
    "A linked list is a linear data structure, in which the elements are not stored at contiguous memory locations. The elements in a linked list are linked using pointers as shown in the below image:\n",
    "\n",
    "In simple words, a linked list consists of nodes where each node contains a data field and a reference(link) to the next node in the list.\n",
    "\n",
    "##### Key Differences Between Array and Linked List:\n",
    "1. An array is the data structure that contains a collection of similar type data elements whereas the Linked list is considered as non-primitive data structure contains a collection of unordered linked elements known as nodes.\n",
    "2. In the array the elements belong to indexes, i.e., if you want to get into the fourth element you have to write the variable name with its index or location within the square bracket.\n",
    "3. In a linked list though, you have to start from the head and work your way through until you get to the fourth element.\n",
    "4. Accessing an element in an array is fast, while Linked list takes linear time, so it is quite a bit slower.\n",
    "5. Operations like insertion and deletion in arrays consume a lot of time. On the other hand, the performance of these operations in Linked lists is fast.\n",
    "6. Arrays are of fixed size. In contrast, Linked lists are dynamic and flexible and can expand and contract its size.\n",
    "7. In an array, memory is assigned during compile time while in a Linked list it is allocated during execution or runtime.\n",
    "9. Elements are stored consecutively in arrays whereas it is stored randomly in Linked lists.\n",
    "10. The requirement of memory is less due to actual data being stored within the index in the array. As against, there is a need for more memory in Linked Lists due to storage of additional next and previous referencing elements.\n",
    "11. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the linked list.\n",
    "\n",
    "\n",
    "##### Conclusion\n",
    "So Linked list provides the following two advantages over arrays\n",
    "1. Dynamic size\n",
    "2. Ease of insertion/deletion\n",
    "\n",
    "Linked lists have following drawbacks:\n",
    "1. Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do a binary search with linked lists.\n",
    "2. Extra memory space for a pointer is required with each element of the list.\n",
    "3. Arrays have better cache locality that can make a pretty big difference in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## btree and binary search\n",
    "\n",
    "Btree order 5:\n",
    "\n",
    "<img src=\"images/btree.svg.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Binary search:\n",
    "\n",
    "<img src=\"images/Binary-Search.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting algorithm\n",
    "\n",
    "- $o(n^2)$ => bubble, insertion, selection sort\n",
    "\n",
    "- $o(n*log(n))$ => merge sort (divide and conquer)\n",
    "\n",
    "https://www.cs.cmu.edu/~adamchik/15-121/lectures/Sorting%20Algorithms/sorting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index in sql\n",
    "\n",
    "An index is helpful for relational databases to speed up queries.\n",
    "\n",
    "For instance, let's take a customer table and index it on the age column.\n",
    "\n",
    "It will build a balanced tree where each node has such structure [age, addresses of corresponding records].\n",
    "\n",
    "Let's consider this filter `WHERE AGE=18`, then if the database holds `N` records and `M` different values for the indexed column, you can achieve this query in `O(log(M))` (binary search) rather than `O(N)`\n",
    "\n",
    "##### The disadvantages of indexes are as follows:\n",
    "\n",
    "1. They decrease performance on inserts, updates, and deletes.\n",
    "2. They take up space (this increases with the number of fields used and the length of the fields).\n",
    "\n",
    "##### What do Clustered and Non clustered index actually mean?\n",
    "\n",
    "With a clustered index the rows are stored physically on the disk in the same order as the index. Therefore, there can be only one clustered index.\n",
    "\n",
    "With a non clustered index there is a second list that has pointers to the physical rows. You can have many non clustered indices, although each new index will increase the time it takes to write new records.\n",
    "\n",
    "It is generally faster to read from a clustered index if you want to get back all the columns. You do not have to go first to the index and then to the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Strategy\n",
    "\n",
    "##### nested join\n",
    "\n",
    "A nested join is a join that compares every record in one table against every record in the other. The complexity is O(MN).\n",
    "\n",
    "This join is efficient when one or both of the tables are extremely small (e.g. < 10 records), which is a very common situation when evaluating queries because some subqueries are written to return only one row.\n",
    "\n",
    "Joins that are not equi-joins* frequently have to do a nested join to evaluate all possible pairs of records, and frequently have result sets of size O(MN) anyway, so then this complexity isn't even bad.\n",
    "\n",
    "Cross-joins (carthesian) are explicitly asking to take every pair of records, and therefore would use this algorithm.\n",
    "\n",
    "##### hash join\n",
    "\n",
    "The classic hash join algorithm for an inner join of two relations proceeds as follows:\n",
    "\n",
    "First, prepare a hash table using the contents of one relation, ideally whichever one is smaller after applying local predicates. This relation is called the build side of the join. The hash table entries are mappings from the value of the (composite) join attribute to the remaining attributes of that row (whichever ones are needed).\n",
    "Once the hash table is built, scan the other relation (the probe side). For each row of the probe relation, find the relevant rows from the build relation by looking in the hash table. Lookup in hashmap are constant compexity.\n",
    "\n",
    "The search algorithm is basically:\n",
    "\n",
    "hash each tuple from R (O(n))\n",
    "\n",
    "hash each tuple from S (O(m))\n",
    "\n",
    "2.1 each time a tuple from S is hashed, look it up in the hashes of R (O(1))\n",
    "\n",
    "2.2 only if a matching hash in found for R, compare the actual tuple values (O(1))\n",
    "\n",
    "A hash join has expected complexity O(M + N), but has unfavorable memory access patterns (random disk access is really bad). It can be really good when one or both the tables is small enough to fit into memory.\n",
    "\n",
    "##### Merge join\n",
    "\n",
    "Merge joins are based on having both tables be sorted according to the keys being joined on, and then doing a O(M+N) merge-like step to determine the matching records.\n",
    "\n",
    "If both tables have an index on the joined columns, then the index already maintains those columns in order and there's no need to sort. The complexity will be O(M + N).\n",
    "\n",
    "If neither table has an index on the joined columns, a sort of both tables will need to happen first, so the complexity will look more like O(M log M + N log N). If the tables are large enough that they don't fit into memory, at least the data access patterns on the disk will be favorable to paging.\n",
    "\n",
    "If only one of the tables has an index on the joined columns, only the one table that doesn't have the index will need to be sorted before the merge step can happen, so the complexity will look like O(M + N log N).\n",
    "\n",
    "\n",
    "###### Sketch \n",
    "\n",
    "The join is not an equi-join?\n",
    "\n",
    "Use nested join\n",
    "The smaller table is extremely small, e.g. less than 10 or 20 rows. Does the larger table have an index on the join columns?\n",
    "\n",
    "If yes, use index join.\n",
    "If no, use nested join.\n",
    "\n",
    "\n",
    "The smaller table is much, much smaller than the larger table (by 100x-1000x or more). Additionally, the larger table has an index on the join columns.\n",
    "\n",
    "Use index join.\n",
    "\n",
    "\n",
    "Both tables have an index on the join columns.\n",
    "\n",
    "Use merge join.\n",
    "\n",
    "\n",
    "The smaller table fits into memory.\n",
    "\n",
    "Use hash join.\n",
    "\n",
    "None of the above.\n",
    "\n",
    "Use merge join after sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational vs non relational\n",
    "\n",
    "A relational database is one where data is stored in the form of a table. Each table has a schema, which is the columns and types a record is required to have. Each schema must have at least one primary key that uniquely identifies that record. In other words, there are no duplicate rows in your database. Moreover, each table can be related to other tables using foreign keys.\n",
    "\n",
    "One important aspect of relational databases is that a change in a schema must be applied to all records. This can sometimes cause breakages and big headaches during migrations. Non-relational databases tackle things in a different way. They are inherently schema-less, which means that records can be saved with different schemas and with a different, nested structure. Records can still have primary keys, but a change in the schema is done on an entry-by-entry basis.\n",
    "\n",
    "If you have a constantly changing schema, such as financial regulatory information, then NoSQL can modify the records and nest related information.\n",
    "\n",
    "Databases also differ in scalability. A non-relational database may be less of a headache to distribute. That’s because a collection of related records can be easily stored on a particular node. On the other hand, relational databases require more thought and usually make use of a master-slave system.\n",
    "\n",
    "\n",
    "## Graph database (GDB)\n",
    "\n",
    "In computing, a graph database (GDB) is a database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data. A key concept of the system is the graph (or edge or relationship). The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation. Graph databases hold the relationships between data as a priority. Querying relationships is fast because they are perpetually stored in the database. Relationships can be intuitively visualized using graph databases, making them useful for heavily inter-connected data.\n",
    "\n",
    "Graph databases are a type of NoSQL database, created to address the limitations of relational databases. While the graph model explicitly lays out the dependencies between nodes of data, the relational model and other NoSQL database models link the data by implicit connections. Graph databases, by design, allow simple and fast retrieval of complex hierarchical structures that are difficult to model in relational systems. \n",
    "\n",
    "The primary difference is that in a graph database, the relationships are stored at the individual record level, while in a relational database, the structure is defined at a higher level (the table definitions).\n",
    "\n",
    "This has important ramifications:\n",
    "\n",
    "A relational database is much faster when operating on huge numbers of records. In a graph database, each record has to be examined individually during a query in order to determine the structure of the data, while this is known ahead of time in a relational database.\n",
    "Relational databases use less storage space, because they don't have to store all of those relationships.\n",
    "Storing all of the relationships at the individual-record level only makes sense if there is going to be a lot of variation in the relationships; otherwise you are just duplicating the same things over and over. This means that graph databases are well-suited to irregular, complex structures. But in the real world, most databases require regular, relatively simple structures. This is why relational databases predominate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column oriented\n",
    "\n",
    "- performance: huge performance in agg\n",
    "- storage requirements: encode column by column, hence same type of data, hence huge compression\n",
    "- ease of modification of the schema: don't need to change each row to add a field, such add a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "$O(1)$ :\tDetermining if a binary number is even or odd; Calculating $\\displaystyle (-1)^{n}$; Using a constant-size lookup table\n",
    "\n",
    "$O(\\log n)$ :\tlogarithmic\tFinding an item in a sorted array with a binary search or a balanced search tree as well as all operations in a Binomial heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth-first Search\n",
    "\n",
    "Depth-first searches are often used in simulations of games (and game-like situations in the real world). In a typical game you can choose one of several possible actions. Each choice leads to further choices, each of which leads to further choices, and so on into an ever-expanding tree-shaped graph of possibilities.\n",
    "\n",
    "For example in games like Chess, tic-tac-toe when you are deciding what move to make, you can mentally imagine a move, then your opponent’s possible responses, then your responses, and so on. You can decide what to do by seeing which move leads to the best outcome.\n",
    "\n",
    "Only some paths in a game tree lead to your win. Some lead to a win by your opponent, when you reach such an ending, you must back up, or backtrack, to a previous node and try a different path. In this way you explore the tree until you find a path with a successful conclusion. Then you make the first move along this path.\n",
    "\n",
    "## Breadth-first search\n",
    "\n",
    "The breadth-first search has an interesting property: It first finds all the vertices that are one edge away from the starting point, then all the vertices that are two edges away, and so on. This is useful if you’re trying to find the shortest path from the starting vertex to a given vertex. You start a BFS, and when you find the specified vertex, you know the path you’ve traced so far is the shortest path to the node. If there were a shorter path, the BFS would have found it already.\n",
    "\n",
    "Breadth-first search can be used for finding the neighbour nodes in peer to peer networks like BitTorrent, GPS systems to find nearby locations, social networking sites to find people in the specified distance and things like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "\n",
    "### Interpreted (python) vs compiled languages (C/Java)\n",
    "\n",
    "The difference between an interpreted and a compiled language lies in the result of the process of interpreting or compiling. An interpreter produces a result from a program, while a compiler produces a program written in assembly language. The assembler of architecture then turns the resulting program into binary code. Assembly language varies for each individual computer, depending upon its architecture. Consequently, compiled programs can only run on computers that have the same architecture as the computer on which they were compiled.\n",
    "\n",
    "### Python: pass by assignment\n",
    "\n",
    "Remember that arguments are passed by assignment in Python. Since assignment just creates references to objects, there’s no alias between an argument name in the caller and callee, and so no call-by-reference per se. You can achieve the desired effect in a number of ways.\n",
    "\n",
    "If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.\n",
    "\n",
    "If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.\n",
    "\n",
    "### Python: id() \n",
    "\n",
    "This identity has to be unique and constant for this object during the lifetime. Two objects with non-overlapping lifetimes may have the same id() value. If we relate this to C, then they are actually the memory address, here in Python it is the unique id. This function is generally used internally in Python.\n",
    "\n",
    "### Python: memory\n",
    "\n",
    "In Python, memory is managed in a private heap space. This means that all the objects and data structures will be located in a private heap. However, the programmer won’t be allowed to access this heap. Instead, the Python interpreter will handle it. At the same time, the core API will enable access to some Python tools for the programmer to start coding. The memory manager will allocate the heap space for the Python objects while the inbuilt garbage collector will recycle all the memory that’s not being used to boost available heap space. \n",
    "\n",
    "### Python: Mutable vs immutable\n",
    "\n",
    "Common immutable type:\n",
    "- numbers: int(), float(), complex()\n",
    "- immutable sequences: str(), tuple(), frozenset(), bytes()\n",
    "\n",
    "Common mutable type (almost everything else):\n",
    "- mutable sequences: list(), bytearray()\n",
    "- set type: set()\n",
    "- mapping type: dict()\n",
    "- classes, class instances\n",
    "All immutable built-in objects in python are hashable. Mutable containers like lists and dictionaries are not hashable while immutable container tuple is hashable\n",
    "\n",
    "Tuples are smaller. Tuples have structure, lists have order, set are list without order\n",
    "\n",
    "### Random questions\n",
    "\n",
    "##### Is there \"switch\" operator in Python?\n",
    "\n",
    "No\n",
    "\n",
    "##### Iterable and generator\n",
    "\n",
    "What is Iterator\n",
    "\n",
    "I hope from the name itself will get to know iterator is something related to for loop(normally we used for iterate objects) right, correct Iterator in Python refers to an object that we can iterate. The iterator consists of the countable number of values and we can get it with one by one value from the object.\n",
    "\n",
    "Benefits of Iterator\n",
    "\n",
    "Iterators are extremely useful, especially if you need to iterate through a large sequence of items. Iterators allow you to iterate through a sequence of items one at a time without having to load all the items into memory at once.\n",
    "\n",
    "Generator\n",
    "\n",
    "Python’s generators provide a convenient way to implement the iterator protocol.\n",
    "\n",
    "\n",
    "##### What advantages do NumPy arrays offer over (nested) Python lists?\n",
    "\n",
    "Python’s lists are efficient general-purpose containers. They support (fairly) efficient insertion, deletion, appending, and concatenation, and Python’s list comprehensions make them easy to construct and manipulate.\n",
    "They have certain limitations: they don’t support “vectorized” operations like elementwise addition and multiplication, and the fact that they can contain objects of differing types mean that Python must store type information for every element, and must execute type dispatching code when operating on each element.\n",
    "NumPy is not just more efficient; it is also more convenient. You get a lot of vector and matrix operations for free, which sometimes allow one to avoid unnecessary work. And they are also efficiently implemented.\n",
    "NumPy array is faster and You get a lot built in with NumPy, FFTs, convolutions, fast searching, basic statistics, linear algebra, histograms, etc. \n",
    "\n",
    "##### How does break, continue and pass work?\n",
    "Break\n",
    "Allows loop termination when some condition is met and the control is transferred to the next statement.\n",
    "\n",
    "Continue\n",
    "Allows skipping some part of a loop when some specific condition is met and the control is transferred to the beginning of the loop\n",
    "\n",
    "Pass\n",
    "Used when you need some block of code syntactically, but you want to skip its execution. This is basically a null operation. Nothing happens when this is executed.\n",
    "\n",
    "\n",
    "\n",
    "##### What is the difference between deep and shallow copy?\n",
    "Shallow copy is used when a new instance type gets created and it keeps the values that are copied in the new instance. Shallow copy is used to copy the reference pointers just like it copies the values. These references point to the original objects and the changes made in any member of the class will also affect the original copy of it. Shallow copy allows faster execution of the program and it depends on the size of the data that is used.\n",
    "Deep copy is used to store the values that are already copied. Deep copy doesn’t copy the reference pointers to the objects. It makes the reference to an object and the new object that is pointed by some other object gets stored. The changes made in the original copy won’t affect any other copy that uses the object. Deep copy makes execution of the program slower due to making certain copies for each object that is been called.\n",
    "\n",
    "\n",
    "\n",
    "##### What is the usage of help() and dir() function in Python?\n",
    "Help() and dir() both functions are accessible from the Python interpreter and used for viewing a consolidated dump of built-in functions. \n",
    "Help() function: The help() function is used to display the documentation string and also facilitates you to see the help related to modules, keywords, attributes, etc.\n",
    "Dir() function: The dir() function is used to display the defined symbols.\n",
    "\n",
    "\n",
    "##### Does python support multiple inheritance?\n",
    "Multiple inheritance means that a class can be derived from more than one parent classes. Python does support multiple inheritance, unlike Java.\n",
    "\n",
    "##### What is Polymorphism in Python?\n",
    "Polymorphism means the ability to take multiple forms. So, for instance, if the parent class has a method named ABC then the child class also can have a method with the same name ABC having its own parameters and variables. Python allows polymorphism.\n",
    "\n",
    "##### Define encapsulation in Python?\n",
    "Encapsulation means binding the code and the data together. A Python class in an example of encapsulation.\n",
    "\n",
    "##### How do you do data abstraction in Python?\n",
    "Data Abstraction is providing only the required details and hiding the implementation from the world. It can be achieved in Python by using interfaces and abstract classes.\n",
    "\n",
    "##### Does python make use of access specifiers?\n",
    "Python does not deprive access to an instance variable or function. Python lays down the concept of prefixing the name of the variable, function or method with a single or double underscore to imitate the behavior of protected and private access specifiers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "\n",
    "### What is a primary key?\n",
    "\n",
    "A primary key is a combination of fields which uniquely specify a row. This is a special kind of unique key, and it has implicit NOT NULL constraint. It means, Primary key values cannot be NULL.\n",
    "\n",
    "### What is a unique key?\n",
    "\n",
    "A Unique key constraint uniquely identified each record in the database. This provides uniqueness for the column or set of columns.\n",
    "\n",
    "A Primary key constraint has automatic unique constraint defined on it. But not, in the case of Unique Key.\n",
    "\n",
    "There can be many unique constraint defined per table, but only one Primary key constraint defined per table.\n",
    "\n",
    "### What is a foreign key?\n",
    "\n",
    "A foreign key is one table which can be related to the primary key of another table. Relationship needs to be created between two tables by referencing foreign key with the primary key of another table.\n",
    "e.g Order table with foreign key person_id from table person\n",
    "\n",
    "### What is a constraint?\n",
    "\n",
    "Constraint can be used to specify the limit on the data type of table. Constraint can be specified while creating or altering the table statement. Sample of constraint are.\n",
    "\n",
    "- NOT NULL.\n",
    "- CHECK.\n",
    "- DEFAULT.\n",
    "- UNIQUE.\n",
    "- PRIMARY KEY.\n",
    "- FOREIGN KEY.\n",
    "\n",
    "### Which operator is used in query for pattern matching?\n",
    "\n",
    "LIKE operator is used for pattern matching, and it can be used as -.\n",
    "\n",
    "- % - Matches zero or more characters.\n",
    "- _ – Matching exactly one character.\n",
    "\n",
    "\n",
    "`Select * from Student where studentname like 'a%'`\n",
    "\n",
    "`Select * from Student where studentname like ‘ami_'`\n",
    "\n",
    "### What is Union, minus and Intersect commands?\n",
    "\n",
    "UNION operator is used to combine the results of two tables, and it eliminates duplicate rows from the tables.\n",
    "\n",
    "UNION ALL does not (eliminate duplicates).\n",
    "\n",
    "MINUS/EXEPT operator is used to return rows from the first query but not from the second query. \n",
    "\n",
    "INTERSECT operator is used to return rows returned by both the queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## behavial\n",
    "\n",
    "- https://365datascience.com/data-engineer-interview-questions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
